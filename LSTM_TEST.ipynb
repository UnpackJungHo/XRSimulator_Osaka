{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/UnpackJungHo/XRSimulator_Osaka/blob/Learning_AI/LSTM_TEST.ipynb",
      "authorship_tag": "ABX9TyM9ORuV3a7iEoV7yjjUgiFn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UnpackJungHo/XRSimulator_Osaka/blob/Learning_AI/LSTM_TEST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from datetime import datetime, timedelta\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from xgboost import XGBRegressor\n",
        "from prophet import Prophet\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class WeatherPredictor:\n",
        "    def __init__(self):\n",
        "        self.lstm_models = {}\n",
        "        self.xgb_models = {}\n",
        "        self.prophet_models = {}\n",
        "        self.scalers = {}\n",
        "        self.label_encoders = {}\n",
        "        self.sequence_length = 24\n",
        "        self.n_future = 6  # 예측 시간 단위\n",
        "\n",
        "    def _get_time_weight(self, hour):\n",
        "        \"\"\"시간대별 가중치 계산\"\"\"\n",
        "        if 6 <= hour < 12:  # 아침\n",
        "            return 1.1\n",
        "        elif 12 <= hour < 18:  # 오후\n",
        "            return 1.05\n",
        "        elif 18 <= hour < 24:  # 저녁\n",
        "            return 0.95\n",
        "        else:  # 새벽\n",
        "            return 0.9\n",
        "\n",
        "    def _get_season_weight(self, month):\n",
        "        \"\"\"계절별 가중치 계산\"\"\"\n",
        "        if 3 <= month < 6:  # 봄\n",
        "            return 1.05\n",
        "        elif 6 <= month < 9:  # 여름\n",
        "            return 1.1\n",
        "        elif 9 <= month < 12:  # 가을\n",
        "            return 1.0\n",
        "        else:  # 겨울\n",
        "            return 0.95\n",
        "\n",
        "    def load_and_preprocess_data(self, training=True):\n",
        "        \"\"\"데이터 로드 및 전처리\"\"\"\n",
        "        try:\n",
        "            if training:\n",
        "                df_2020 = pd.read_excel('2020_weather.xlsx', dtype={'DateTime(YYYYMMDDHHMI)': str})\n",
        "                df_2021 = pd.read_excel('2021_weather.xlsx', dtype={'DateTime(YYYYMMDDHHMI)': str})\n",
        "                df_2022 = pd.read_excel('2022_weather.xlsx', dtype={'DateTime(YYYYMMDDHHMI)': str})\n",
        "                print(\"학습 데이터 로드 완료 (2020-2022)\")\n",
        "                df = pd.concat([df_2020, df_2021, df_2022], ignore_index=True)\n",
        "            else:\n",
        "                df = pd.read_excel('2023_weather.xlsx', dtype={'DateTime(YYYYMMDDHHMI)': str})\n",
        "                print(\"검증 데이터 로드 완료 (2023)\")\n",
        "\n",
        "            df = self._basic_preprocessing(df)\n",
        "            df = self._create_advanced_features(df)\n",
        "            df = self._handle_outliers(df)\n",
        "            df = self._handle_missing_values(df)\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"데이터 로드 중 오류 발생:\", e)\n",
        "            raise e\n",
        "\n",
        "    def _basic_preprocessing(self, df):\n",
        "        \"\"\"기본 전처리 작업\"\"\"\n",
        "        try:\n",
        "            # DateTime 변환\n",
        "            df['DateTime(YYYYMMDDHHMI)'] = pd.to_datetime(df['DateTime(YYYYMMDDHHMI)'],\n",
        "                                                        format='%Y%m%d%H%M')\n",
        "            df = df.set_index('DateTime(YYYYMMDDHHMI)')\n",
        "\n",
        "            # 시간 관련 특성 추가\n",
        "            df['hour'] = df.index.hour\n",
        "            df['month'] = df.index.month\n",
        "            df['day'] = df.index.day\n",
        "            df['dayofweek'] = df.index.dayofweek\n",
        "            df['dayofyear'] = df.index.dayofyear\n",
        "            df['is_weekend'] = df['dayofweek'].isin([5, 6]).astype(int)\n",
        "\n",
        "            # 계절성 특성 추가\n",
        "            df['year_sin'] = np.sin(2 * np.pi * df['dayofyear']/365)\n",
        "            df['year_cos'] = np.cos(2 * np.pi * df['dayofyear']/365)\n",
        "            df['day_sin'] = np.sin(2 * np.pi * df['hour']/24)\n",
        "            df['day_cos'] = np.cos(2 * np.pi * df['hour']/24)\n",
        "            df['month_sin'] = np.sin(2 * np.pi * df['month']/12)\n",
        "            df['month_cos'] = np.cos(2 * np.pi * df['month']/12)\n",
        "\n",
        "            # 계절 추가\n",
        "            df['season'] = pd.cut(df['month'],\n",
        "                                bins=[0,3,6,9,12],\n",
        "                                labels=['winter','spring','summer','fall'])\n",
        "\n",
        "            # 범주형 변수 인코딩\n",
        "            categorical_columns = ['WW', 'CT', 'season']\n",
        "            for col in categorical_columns:\n",
        "                if df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
        "                    if col not in self.label_encoders:\n",
        "                        self.label_encoders[col] = LabelEncoder()\n",
        "                        self.label_encoders[col].fit(df[col].astype(str))\n",
        "\n",
        "                    if col in ['WW', 'CT']:  # season은 고정된 카테고리이므로 제외\n",
        "                        unique_labels = set(df[col].astype(str).unique())\n",
        "                        known_labels = set(self.label_encoders[col].classes_)\n",
        "                        new_labels = unique_labels - known_labels\n",
        "\n",
        "                        if new_labels:\n",
        "                            print(f\"\\n{col}에서 발견된 새로운 레이블: {new_labels}\")\n",
        "                            for new_label in new_labels:\n",
        "                                df.loc[df[col].astype(str) == new_label, col] = self.label_encoders[col].classes_[0]\n",
        "\n",
        "                    df[col] = self.label_encoders[col].transform(df[col].astype(str))\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"기본 전처리 중 오류 발생:\", e)\n",
        "            raise e\n",
        "\n",
        "    def _create_advanced_features(self, df):\n",
        "        \"\"\"고급 특성 생성\"\"\"\n",
        "        # 시계열 특성\n",
        "        for col in ['TA', 'WS', 'HM', 'RN', 'WD']:\n",
        "            # 이동평균 (다양한 윈도우 크기)\n",
        "            windows = [1, 2, 3, 6, 12, 24]\n",
        "            for w in windows:\n",
        "                df[f'{col}_MA{w}'] = df[col].rolling(window=w).mean()\n",
        "\n",
        "            # 변화율\n",
        "            df[f'{col}_change'] = df[col].diff()\n",
        "            df[f'{col}_change_rate'] = df[col].pct_change()\n",
        "            df[f'{col}_change_acc'] = df[col].diff().diff()\n",
        "\n",
        "            # 시간별/일별 통계\n",
        "            df[f'{col}_hour_mean'] = df.groupby('hour')[col].transform('mean')\n",
        "            df[f'{col}_hour_std'] = df.groupby('hour')[col].transform('std')\n",
        "\n",
        "            # 시간대별 평균\n",
        "            for period in ['morning', 'afternoon', 'evening', 'night']:\n",
        "                if period == 'morning':\n",
        "                    mask = (df['hour'] >= 6) & (df['hour'] < 12)\n",
        "                elif period == 'afternoon':\n",
        "                    mask = (df['hour'] >= 12) & (df['hour'] < 18)\n",
        "                elif period == 'evening':\n",
        "                    mask = (df['hour'] >= 18) & (df['hour'] < 24)\n",
        "                else:  # night\n",
        "                    mask = (df['hour'] < 6)\n",
        "                df[f'{col}_{period}_mean'] = df[col][mask].mean()\n",
        "\n",
        "            # 계절별 통계\n",
        "            df[f'{col}_season_mean'] = df.groupby('season')[col].transform('mean')\n",
        "            df[f'{col}_season_std'] = df.groupby('season')[col].transform('std')\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _handle_outliers(self, df):\n",
        "        \"\"\"이상치 처리\"\"\"\n",
        "        numerical_columns = ['TA', 'WS', 'HM', 'RN']\n",
        "        for col in numerical_columns:\n",
        "            Q1 = df[col].quantile(0.25)\n",
        "            Q3 = df[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            df[col] = df[col].clip(lower_bound, upper_bound)\n",
        "        return df\n",
        "\n",
        "    def _handle_missing_values(self, df):\n",
        "        \"\"\"결측치 처리\"\"\"\n",
        "        numerical_columns = ['TA', 'WS', 'HM', 'RN']\n",
        "        for col in numerical_columns:\n",
        "            # 시간대별, 계절별 평균으로 결측치 처리\n",
        "            df[col] = df.groupby(['hour', 'season'])[col].transform(\n",
        "                lambda x: x.fillna(x.mean())\n",
        "            )\n",
        "        df.fillna(df.mean(), inplace=True)\n",
        "        return df\n",
        "\n",
        "    def _prepare_data(self, df, target):\n",
        "        \"\"\"데이터 준비 및 스케일링\"\"\"\n",
        "        try:\n",
        "            # 인덱스 중복 확인 및 처리\n",
        "            if df.index.duplicated().any():\n",
        "                print(\"중복된 인덱스 발견. 첫 번째 값만 유지합니다.\")\n",
        "                df = df[~df.index.duplicated(keep='first')]\n",
        "\n",
        "            # 특성 선택\n",
        "            feature_columns = [col for col in df.columns\n",
        "                              if col not in ['DateTime(YYYYMMDDHHMI)']]\n",
        "\n",
        "            # 무한대 값 처리\n",
        "            data = df[feature_columns].copy()\n",
        "            data = data.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "            # 이상치 처리\n",
        "            for col in data.columns:\n",
        "                if data[col].dtype in ['int64', 'float64']:\n",
        "                    Q1 = data[col].quantile(0.25)\n",
        "                    Q3 = data[col].quantile(0.75)\n",
        "                    IQR = Q3 - Q1\n",
        "                    lower_bound = Q1 - 1.5 * IQR\n",
        "                    upper_bound = Q3 + 1.5 * IQR\n",
        "                    data[col] = data[col].clip(lower_bound, upper_bound)\n",
        "\n",
        "            # 결측치 처리\n",
        "            for col in data.columns:\n",
        "                if data[col].dtype in ['int64', 'float64']:\n",
        "                    data[col] = data.groupby(['hour', 'season'])[col].transform(\n",
        "                        lambda x: x.fillna(x.mean())\n",
        "                    )\n",
        "            data = data.fillna(data.mean())\n",
        "\n",
        "            # 각 변수별 개별 스케일링\n",
        "            scaled_data = pd.DataFrame(index=data.index)  # 인덱스 유지\n",
        "            scalers = {}\n",
        "\n",
        "            for col in data.columns:\n",
        "                if data[col].dtype in ['int64', 'float64']:\n",
        "                    scaler = MinMaxScaler()\n",
        "                    scaled_values = scaler.fit_transform(data[col].values.reshape(-1, 1)).flatten()\n",
        "                    scaled_data[col] = scaled_values\n",
        "                    scalers[col] = scaler\n",
        "                else:\n",
        "                    scaled_data[col] = data[col]\n",
        "\n",
        "            self.scalers[target] = scalers\n",
        "            return scaled_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"데이터 준비 중 오류 발생: {str(e)}\")\n",
        "            print(f\"문제가 발생한 데이터 형태:\")\n",
        "            print(df.info())\n",
        "            print(\"\\n데이터 샘플:\")\n",
        "            print(df.head())\n",
        "            raise e\n",
        "\n",
        "    def create_sequences(self, data, target_col):\n",
        "        \"\"\"시계열 시퀀스 생성 (직접 예측 방식)\"\"\"\n",
        "        X, y = [], []\n",
        "        for i in range(len(data) - self.sequence_length - self.n_future + 1):\n",
        "            X.append(data[i:(i + self.sequence_length)])\n",
        "            y.append(data[target_col].iloc[i + self.sequence_length:i + self.sequence_length + self.n_future])\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def create_lstm_model(self, input_shape):\n",
        "        \"\"\"단순화된 LSTM 모델 생성\"\"\"\n",
        "        model = Sequential([\n",
        "            LSTM(64, input_shape=input_shape),\n",
        "            Dropout(0.2),\n",
        "            Dense(32, activation='relu'),\n",
        "            Dense(self.n_future)\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        return model\n",
        "\n",
        "    def prepare_prophet_data(self, df, target):\n",
        "        \"\"\"Prophet용 데이터 준비\"\"\"\n",
        "        prophet_df = pd.DataFrame({\n",
        "            'ds': df.index,\n",
        "            'y': df[target]\n",
        "        })\n",
        "        return prophet_df\n",
        "\n",
        "    def train_prophet_model(self, df, target):\n",
        "        \"\"\"Prophet 모델 학습\"\"\"\n",
        "        prophet_df = self.prepare_prophet_data(df, target)\n",
        "        model = Prophet(\n",
        "            yearly_seasonality=True,\n",
        "            weekly_seasonality=True,\n",
        "            daily_seasonality=True,\n",
        "            changepoint_prior_scale=0.05\n",
        "        )\n",
        "        model.fit(prophet_df)\n",
        "        return model\n",
        "\n",
        "    def train_models(self, df):\n",
        "        \"\"\"모델 학습\"\"\"\n",
        "        target_columns = ['TA', 'RN', 'WS', 'HM', 'WD']\n",
        "\n",
        "        # 기본 전처리\n",
        "        df = df.copy()\n",
        "        df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "        # 시계열 교차 검증 설정\n",
        "        tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "        for target in target_columns:\n",
        "            print(f\"\\n{target} 모델 학습 중...\")\n",
        "\n",
        "            try:\n",
        "                # 데이터 준비\n",
        "                scaled_data = self._prepare_data(df, target)\n",
        "\n",
        "                # 데이터 검증\n",
        "                if scaled_data.isnull().any().any():\n",
        "                    print(f\"경고: {target}에 대한 전처리 후에도 결측치가 존재합니다.\")\n",
        "                    print(\"결측치가 있는 열:\", scaled_data.columns[scaled_data.isnull().any()].tolist())\n",
        "                    scaled_data = scaled_data.fillna(scaled_data.mean())\n",
        "\n",
        "                if np.isinf(scaled_data.values).any():\n",
        "                    print(f\"경고: {target}에 대한 전처리 후에도 무한대 값이 존재합니다.\")\n",
        "                    scaled_data = scaled_data.replace([np.inf, -np.inf], 0)\n",
        "\n",
        "                # LSTM 데이터 준비\n",
        "                X, y = self.create_sequences(scaled_data, target)\n",
        "\n",
        "                # LSTM 모델 학습\n",
        "                lstm_model = self.create_lstm_model((self.sequence_length, X.shape[2]))\n",
        "\n",
        "                # 교차 검증을 통한 LSTM 학습\n",
        "                for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
        "                    print(f\"\\nFold {fold + 1}/5\")\n",
        "                    X_train, X_val = X[train_idx], X[val_idx]\n",
        "                    y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "                    # Early Stopping 설정\n",
        "                    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "                        monitor='val_loss',\n",
        "                        patience=5,\n",
        "                        restore_best_weights=True\n",
        "                    )\n",
        "\n",
        "                    # LSTM 모델 학습\n",
        "                    lstm_model.fit(\n",
        "                        X_train, y_train,\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        epochs=50,\n",
        "                        batch_size=32,\n",
        "                        callbacks=[early_stopping],\n",
        "                        verbose=1\n",
        "                    )\n",
        "\n",
        "                self.lstm_models[target] = lstm_model\n",
        "\n",
        "                # XGBoost 모델 학습\n",
        "                xgb_models = []\n",
        "                for i in range(self.n_future):\n",
        "                    xgb_model = XGBRegressor(\n",
        "                        n_estimators=100,\n",
        "                        learning_rate=0.1,\n",
        "                        max_depth=5,\n",
        "                        objective='reg:squarederror'\n",
        "                    )\n",
        "\n",
        "                    # i+1 시점 후의 값을 예측하도록 학습\n",
        "                    X_xgb = scaled_data.values[:-self.n_future]\n",
        "                    y_xgb = scaled_data[target].values[i+1:-(self.n_future-i-1) if self.n_future-i-1 > 0 else None]\n",
        "\n",
        "                    xgb_model.fit(X_xgb, y_xgb)\n",
        "                    xgb_models.append(xgb_model)\n",
        "\n",
        "                self.xgb_models[target] = xgb_models\n",
        "\n",
        "                # Prophet 모델 학습\n",
        "                prophet_model = self.train_prophet_model(df, target)\n",
        "                self.prophet_models[target] = prophet_model\n",
        "\n",
        "                # 모델 성능 평가\n",
        "                self._evaluate_models(scaled_data, target)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\n{target} 모델 학습 중 오류 발생:\")\n",
        "                print(f\"오류 메시지: {str(e)}\")\n",
        "    def _evaluate_models(self, data, target):\n",
        "        \"\"\"모델 성능 평가\"\"\"\n",
        "        X, y = self.create_sequences(data, target)\n",
        "        test_size = len(X) // 5  # 20%를 테스트 셋으로 사용\n",
        "\n",
        "        X_test = X[-test_size:]\n",
        "        y_test = y[-test_size:]\n",
        "\n",
        "        try:\n",
        "            # LSTM 예측\n",
        "            lstm_pred = self.lstm_models[target].predict(X_test)\n",
        "\n",
        "            # XGBoost 예측 (n_future 시점에 대한 예측으로 수정)\n",
        "            xgb_pred = np.zeros((len(X_test), self.n_future))\n",
        "            for i in range(self.n_future):\n",
        "                xgb_pred[:, i] = self.xgb_models[target][i].predict(X_test[:, -1, :])\n",
        "\n",
        "            # Prophet 예측\n",
        "            prophet_pred = np.zeros((len(X_test), self.n_future))\n",
        "            future_dates = pd.date_range(\n",
        "                start=data.index[-1],\n",
        "                periods=self.n_future + 1,\n",
        "                freq='H'\n",
        "            )[1:]\n",
        "\n",
        "            for i in range(len(X_test)):\n",
        "                future_df = pd.DataFrame({'ds': future_dates})\n",
        "                prophet_forecast = self.prophet_models[target].predict(future_df)\n",
        "                prophet_pred[i] = prophet_forecast['yhat'].values\n",
        "\n",
        "            # 앙상블 예측 (가중 평균)\n",
        "            ensemble_pred = (0.4 * lstm_pred +\n",
        "                           0.4 * xgb_pred +\n",
        "                           0.2 * prophet_pred)\n",
        "\n",
        "            # 성능 평가\n",
        "            mse = mean_squared_error(y_test, ensemble_pred)\n",
        "            mae = mean_absolute_error(y_test, ensemble_pred)\n",
        "            r2 = r2_score(y_test.reshape(-1), ensemble_pred.reshape(-1))\n",
        "\n",
        "            print(f\"\\n{target} 앙상블 모델 성능:\")\n",
        "            print(f\"MSE: {mse:.4f}\")\n",
        "            print(f\"MAE: {mae:.4f}\")\n",
        "            print(f\"R2 Score: {r2:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n{target} 모델 평가 중 오류 발생:\")\n",
        "            print(f\"오류 메시지: {str(e)}\")\n",
        "            print(f\"LSTM 예측 shape: {lstm_pred.shape}\")\n",
        "            print(f\"XGBoost 예측 shape: {xgb_pred.shape}\")\n",
        "            print(f\"테스트 데이터 shape: {y_test.shape}\")\n",
        "\n",
        "    def predict_and_evaluate(self, input_time, validation_data):\n",
        "        \"\"\"예측 수행 및 평가\"\"\"\n",
        "        input_datetime = pd.to_datetime(input_time, format='%Y/%m/%d/%H:%M')\n",
        "\n",
        "        # 입력 시퀀스 준비\n",
        "        past_data = validation_data[validation_data.index <= input_datetime].tail(self.sequence_length)\n",
        "\n",
        "        if len(past_data) < self.sequence_length:\n",
        "            print(f\"예측을 위해 최소 {self.sequence_length}시간의 데이터가 필요합니다.\")\n",
        "            return None\n",
        "\n",
        "        predictions = []\n",
        "        target_columns = ['TA', 'RN', 'WS', 'HM', 'WD']\n",
        "\n",
        "        for hour in range(self.n_future):\n",
        "            next_time = input_datetime + timedelta(hours=hour)\n",
        "            hour_prediction = {'DateTime': next_time}\n",
        "\n",
        "            for target in target_columns:\n",
        "                # 데이터 준비\n",
        "                scaled_data = self._prepare_data(past_data, target)\n",
        "\n",
        "                # LSTM 예측\n",
        "                X_lstm = scaled_data.values.reshape(1, self.sequence_length, -1)\n",
        "                lstm_pred = self.lstm_models[target].predict(X_lstm, verbose=0)[0][hour]\n",
        "\n",
        "                # XGBoost 예측\n",
        "                xgb_pred = self.xgb_models[target][hour].predict(scaled_data.iloc[-1:].values)[0]\n",
        "\n",
        "                # Prophet 예측\n",
        "                future_df = pd.DataFrame({'ds': [next_time]})\n",
        "                prophet_pred = self.prophet_models[target].predict(future_df)['yhat'].values[0]\n",
        "\n",
        "                # 앙상블 예측 (가중 평균)\n",
        "                ensemble_pred = (0.4 * lstm_pred +\n",
        "                               0.4 * xgb_pred +\n",
        "                               0.2 * prophet_pred)\n",
        "\n",
        "                # 시간대/계절 가중치 적용\n",
        "                time_weight = self._get_time_weight(next_time.hour)\n",
        "                season_weight = self._get_season_weight(next_time.month)\n",
        "                final_pred = ensemble_pred * time_weight * season_weight\n",
        "\n",
        "                # 역스케일링\n",
        "                scaler = self.scalers[target][target]\n",
        "                final_pred = scaler.inverse_transform([[final_pred]])[0][0]\n",
        "\n",
        "                hour_prediction[f'{target}_pred'] = final_pred\n",
        "\n",
        "                # 실제값 찾기\n",
        "                actual_row = validation_data[validation_data.index == next_time]\n",
        "                if not actual_row.empty:\n",
        "                    hour_prediction[f'{target}_actual'] = actual_row[target].iloc[0]\n",
        "                else:\n",
        "                    hour_prediction[f'{target}_actual'] = None\n",
        "\n",
        "            predictions.append(hour_prediction)\n",
        "\n",
        "        results_df = pd.DataFrame(predictions)\n",
        "\n",
        "        # 예측 성능 평가\n",
        "        print(\"\\n예측 성능 평가:\")\n",
        "        for target in target_columns:\n",
        "            mask = results_df[f'{target}_actual'].notna()\n",
        "            if mask.any():\n",
        "                mae = mean_absolute_error(\n",
        "                    results_df[mask][f'{target}_actual'],\n",
        "                    results_df[mask][f'{target}_pred']\n",
        "                )\n",
        "                mse = mean_squared_error(\n",
        "                    results_df[mask][f'{target}_actual'],\n",
        "                    results_df[mask][f'{target}_pred']\n",
        "                )\n",
        "                r2 = r2_score(\n",
        "                    results_df[mask][f'{target}_actual'],\n",
        "                    results_df[mask][f'{target}_pred']\n",
        "                )\n",
        "\n",
        "                print(f\"\\n{target} 예측 성능:\")\n",
        "                print(f\"MAE: {mae:.4f}\")\n",
        "                print(f\"MSE: {mse:.4f}\")\n",
        "                print(f\"R2 Score: {r2:.4f}\")\n",
        "\n",
        "        return results_df\n",
        "\n",
        "def main():\n",
        "    # 예측기 인스턴스 생성\n",
        "    predictor = WeatherPredictor()\n",
        "\n",
        "    # 학습 데이터 로드 및 전처리\n",
        "    print(\"학습 데이터 로드 및 전처리 중...\")\n",
        "    train_df = predictor.load_and_preprocess_data(training=True)\n",
        "\n",
        "    # 검증 데이터 로드\n",
        "    print(\"\\n검증 데이터 로드 중...\")\n",
        "    validation_df = predictor.load_and_preprocess_data(training=False)\n",
        "\n",
        "    # 모델 학습\n",
        "    print(\"\\n모델 학습 시작...\")\n",
        "    predictor.train_models(train_df)\n",
        "\n",
        "    while True:\n",
        "        # 사용자로부터 날짜 입력 받기\n",
        "        input_time = input(\"\\n예측할 날짜와 시간을 입력하세요 (형식: YYYY/MM/DD/HH:MM, 종료는 'q'): \")\n",
        "\n",
        "        if input_time.lower() == 'q':\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            # 예측 수행 및 평가\n",
        "            results = predictor.predict_and_evaluate(input_time, validation_df)\n",
        "\n",
        "            if results is not None:\n",
        "                print(\"\\n예측 결과:\")\n",
        "                pd.set_option('display.max_columns', None)\n",
        "                print(results[['DateTime'] +\n",
        "                            [col for col in results.columns if 'pred' in col or 'actual' in col]])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"오류 발생: {str(e)}\")\n",
        "            print(\"올바른 형식으로 다시 입력해주세요.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "td4KBo_DCAK1",
        "outputId": "c8fa720a-d906-4c9d-9dc9-9907bb7b0085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 로드 및 전처리 중...\n",
            "학습 데이터 로드 완료 (2020-2022)\n",
            "\n",
            "검증 데이터 로드 중...\n",
            "검증 데이터 로드 완료 (2023)\n",
            "\n",
            "WW에서 발견된 새로운 레이블: {'19060502', '601', '400601', '4240', '190501', '19060201', '160201', '1602', '190602', '1601'}\n",
            "\n",
            "CT에서 발견된 새로운 레이블: {'CuCs', 'CuAcCi'}\n",
            "\n",
            "모델 학습 시작...\n",
            "\n",
            "TA 모델 학습 중...\n",
            "중복된 인덱스 발견. 첫 번째 값만 유지합니다.\n",
            "\n",
            "Fold 1/5\n",
            "Epoch 1/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0685 - val_loss: 0.0789\n",
            "Epoch 2/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0087 - val_loss: 0.0738\n",
            "Epoch 3/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0061 - val_loss: 0.0691\n",
            "Epoch 4/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0616\n",
            "Epoch 5/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0040 - val_loss: 0.0653\n",
            "Epoch 6/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0671\n",
            "Epoch 7/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0648\n",
            "Epoch 8/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0671\n",
            "Epoch 9/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0663\n",
            "\n",
            "Fold 2/5\n",
            "Epoch 1/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0113 - val_loss: 0.0055\n",
            "Epoch 2/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0036\n",
            "Epoch 3/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 4/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0034\n",
            "Epoch 5/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0034\n",
            "Epoch 6/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0039\n",
            "Epoch 7/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 8/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0030\n",
            "Epoch 9/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 0.0032\n",
            "Epoch 10/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 11/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 0.0041\n",
            "Epoch 12/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0030\n",
            "\n",
            "Fold 3/5\n",
            "Epoch 1/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 0.0043\n",
            "Epoch 2/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0045\n",
            "Epoch 3/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0035\n",
            "Epoch 4/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 5/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 6/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0031\n",
            "Epoch 7/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0012 - val_loss: 0.0038\n",
            "Epoch 8/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 0.0046\n",
            "Epoch 9/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0010 - val_loss: 0.0064\n",
            "Epoch 10/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 9.7994e-04 - val_loss: 0.0064\n",
            "Epoch 11/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.6190e-04 - val_loss: 0.0032\n",
            "\n",
            "Fold 4/5\n",
            "Epoch 1/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 0.0027\n",
            "Epoch 2/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0023\n",
            "Epoch 3/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0024\n",
            "Epoch 4/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.8214e-04 - val_loss: 0.0020\n",
            "Epoch 5/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.6751e-04 - val_loss: 0.0021\n",
            "Epoch 6/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 8.7720e-04 - val_loss: 0.0033\n",
            "Epoch 7/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 8.6863e-04 - val_loss: 0.0031\n",
            "Epoch 8/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 7.9662e-04 - val_loss: 0.0028\n",
            "Epoch 9/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 8.4323e-04 - val_loss: 0.0031\n",
            "\n",
            "Fold 5/5\n",
            "Epoch 1/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 9.5838e-04 - val_loss: 0.0054\n",
            "Epoch 2/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 8.5714e-04 - val_loss: 0.0043\n",
            "Epoch 3/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 8.3075e-04 - val_loss: 0.0047\n",
            "Epoch 4/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 7.8590e-04 - val_loss: 0.0029\n",
            "Epoch 5/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 7.3243e-04 - val_loss: 0.0047\n",
            "Epoch 6/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 7.5741e-04 - val_loss: 0.0059\n",
            "Epoch 7/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 7.1568e-04 - val_loss: 0.0042\n",
            "Epoch 8/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 6.9393e-04 - val_loss: 0.0048\n",
            "Epoch 9/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 6.6029e-04 - val_loss: 0.0053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp4gj8q6rn/wp5rwv5k.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp4gj8q6rn/glvw_66b.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=5899', 'data', 'file=/tmp/tmp4gj8q6rn/wp5rwv5k.json', 'init=/tmp/tmp4gj8q6rn/glvw_66b.json', 'output', 'file=/tmp/tmp4gj8q6rn/prophet_modelt1j97svj/prophet_model-20241227120740.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "12:07:40 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "12:07:53 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "TA 앙상블 모델 성능:\n",
            "MSE: 2.9970\n",
            "MAE: 1.7275\n",
            "R2 Score: -77.3652\n",
            "\n",
            "RN 모델 학습 중...\n",
            "중복된 인덱스 발견. 첫 번째 값만 유지합니다.\n",
            "\n",
            "Fold 1/5\n",
            "Epoch 1/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0294 - val_loss: 6.4845e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.5405e-04 - val_loss: 5.0082e-05\n",
            "Epoch 3/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 8.9869e-05 - val_loss: 8.0801e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.7209e-05 - val_loss: 1.2997e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.4191e-05 - val_loss: 1.0558e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.1838e-06 - val_loss: 8.6743e-05\n",
            "Epoch 7/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.9010e-06 - val_loss: 1.1935e-04\n",
            "\n",
            "Fold 2/5\n",
            "Epoch 1/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1493e-04 - val_loss: 1.0188e-06\n",
            "Epoch 2/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 7.8752e-06 - val_loss: 1.1178e-06\n",
            "Epoch 3/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 2.7749e-06 - val_loss: 7.2994e-07\n",
            "Epoch 4/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.6184e-06 - val_loss: 7.2898e-07\n",
            "Epoch 5/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 8.4525e-07 - val_loss: 7.0058e-07\n",
            "Epoch 6/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 3.8697e-07 - val_loss: 7.1363e-07\n",
            "Epoch 7/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 3.1207e-07 - val_loss: 8.1804e-07\n",
            "Epoch 8/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 2.8377e-07 - val_loss: 8.5851e-07\n",
            "Epoch 9/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 8.6261e-07 - val_loss: 7.8999e-07\n",
            "Epoch 10/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 2.5109e-07 - val_loss: 7.5669e-07\n",
            "\n",
            "Fold 3/5\n",
            "Epoch 1/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.0595e-07 - val_loss: 4.9737e-09\n",
            "Epoch 2/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 5.2499e-07 - val_loss: 9.4126e-10\n",
            "Epoch 3/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 8.6504e-08 - val_loss: 8.8355e-11\n",
            "Epoch 4/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.9819e-08 - val_loss: 1.0553e-09\n",
            "Epoch 5/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.2782e-08 - val_loss: 6.5876e-10\n",
            "Epoch 6/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 4.2197e-08 - val_loss: 3.4053e-11\n",
            "Epoch 7/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1.6873e-07 - val_loss: 8.9815e-11\n",
            "Epoch 8/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1.1376e-07 - val_loss: 5.6245e-09\n",
            "Epoch 9/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.2496e-08 - val_loss: 4.6547e-09\n",
            "Epoch 10/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 1.4092e-07 - val_loss: 1.4563e-13\n",
            "Epoch 11/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.2036e-09 - val_loss: 5.6428e-16\n",
            "Epoch 12/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 2.3526e-09 - val_loss: 3.2956e-09\n",
            "Epoch 13/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 4.8645e-09 - val_loss: 1.0490e-11\n",
            "Epoch 14/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 3.0540e-09 - val_loss: 1.3678e-09\n",
            "Epoch 15/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 7.0210e-08 - val_loss: 5.5582e-12\n",
            "Epoch 16/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 8.2992e-09 - val_loss: 6.3669e-10\n",
            "\n",
            "Fold 4/5\n",
            "Epoch 1/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.2176e-08 - val_loss: 1.5485e-15\n",
            "Epoch 2/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.0807e-08 - val_loss: 1.8949e-10\n",
            "Epoch 3/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1.8982e-06 - val_loss: 1.3317e-09\n",
            "Epoch 4/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.2945e-08 - val_loss: 2.3331e-10\n",
            "Epoch 5/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.6155e-09 - val_loss: 1.4775e-10\n",
            "Epoch 6/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 2.0627e-08 - val_loss: 7.2201e-11\n",
            "\n",
            "Fold 5/5\n",
            "Epoch 1/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 2.4820e-09 - val_loss: 8.3474e-13\n",
            "Epoch 2/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 5.2809e-07 - val_loss: 2.5979e-21\n",
            "Epoch 3/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 1.2466e-09 - val_loss: 1.1326e-11\n",
            "Epoch 4/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 7.5498e-13 - val_loss: 0.0000e+00\n",
            "Epoch 5/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 1.4810e-09 - val_loss: 4.8419e-28\n",
            "Epoch 6/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 4.3631e-29 - val_loss: 0.0000e+00\n",
            "Epoch 7/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 8/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 2.4676e-10 - val_loss: 4.1871e-19\n",
            "Epoch 9/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 5.2875e-10 - val_loss: 2.2657e-08\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "RN 앙상블 모델 성능:\n",
            "MSE: 3.2400\n",
            "MAE: 1.8000\n",
            "R2 Score: 0.0000\n",
            "\n",
            "WS 모델 학습 중...\n",
            "중복된 인덱스 발견. 첫 번째 값만 유지합니다.\n",
            "\n",
            "Fold 1/5\n",
            "Epoch 1/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2872 - val_loss: 0.0343\n",
            "Epoch 2/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0438 - val_loss: 0.0367\n",
            "Epoch 3/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0327 - val_loss: 0.0414\n",
            "Epoch 4/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0297 - val_loss: 0.0394\n",
            "Epoch 5/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0282 - val_loss: 0.0356\n",
            "Epoch 6/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0266 - val_loss: 0.0327\n",
            "Epoch 7/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0247 - val_loss: 0.0364\n",
            "Epoch 8/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0257 - val_loss: 0.0350\n",
            "Epoch 9/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0241 - val_loss: 0.0331\n",
            "Epoch 10/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0237 - val_loss: 0.0297\n",
            "Epoch 11/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0237 - val_loss: 0.0312\n",
            "Epoch 12/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0226 - val_loss: 0.0309\n",
            "Epoch 13/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0227 - val_loss: 0.0304\n",
            "Epoch 14/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0222 - val_loss: 0.0301\n",
            "Epoch 15/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0220 - val_loss: 0.0276\n",
            "Epoch 16/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0214 - val_loss: 0.0320\n",
            "Epoch 17/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0212 - val_loss: 0.0289\n",
            "Epoch 18/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0214 - val_loss: 0.0243\n",
            "Epoch 19/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0203 - val_loss: 0.0297\n",
            "Epoch 20/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0206 - val_loss: 0.0321\n",
            "Epoch 21/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0201 - val_loss: 0.0247\n",
            "Epoch 22/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0199 - val_loss: 0.0321\n",
            "Epoch 23/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0200 - val_loss: 0.0286\n",
            "\n",
            "Fold 2/5\n",
            "Epoch 1/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0223 - val_loss: 0.0259\n",
            "Epoch 2/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0218 - val_loss: 0.0247\n",
            "Epoch 3/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0210 - val_loss: 0.0253\n",
            "Epoch 4/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0208 - val_loss: 0.0254\n",
            "Epoch 5/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0203 - val_loss: 0.0253\n",
            "Epoch 6/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0203 - val_loss: 0.0252\n",
            "Epoch 7/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0201 - val_loss: 0.0260\n",
            "\n",
            "Fold 3/5\n",
            "Epoch 1/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0225 - val_loss: 0.0214\n",
            "Epoch 2/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0221 - val_loss: 0.0189\n",
            "Epoch 3/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0213 - val_loss: 0.0187\n",
            "Epoch 4/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0209 - val_loss: 0.0183\n",
            "Epoch 5/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0205 - val_loss: 0.0189\n",
            "Epoch 6/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0205 - val_loss: 0.0183\n",
            "Epoch 7/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0202 - val_loss: 0.0181\n",
            "Epoch 8/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0201 - val_loss: 0.0177\n",
            "Epoch 9/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0199 - val_loss: 0.0188\n",
            "Epoch 10/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0196 - val_loss: 0.0190\n",
            "Epoch 11/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0199 - val_loss: 0.0182\n",
            "Epoch 12/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0193 - val_loss: 0.0181\n",
            "Epoch 13/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0190 - val_loss: 0.0187\n",
            "\n",
            "Fold 4/5\n",
            "Epoch 1/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0197 - val_loss: 0.0205\n",
            "Epoch 2/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0196 - val_loss: 0.0203\n",
            "Epoch 3/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0188 - val_loss: 0.0232\n",
            "Epoch 4/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0191 - val_loss: 0.0228\n",
            "Epoch 5/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0191 - val_loss: 0.0222\n",
            "Epoch 6/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0188 - val_loss: 0.0214\n",
            "Epoch 7/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0188 - val_loss: 0.0220\n",
            "\n",
            "Fold 5/5\n",
            "Epoch 1/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0198 - val_loss: 0.0178\n",
            "Epoch 2/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0196 - val_loss: 0.0177\n",
            "Epoch 3/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0194 - val_loss: 0.0181\n",
            "Epoch 4/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0191 - val_loss: 0.0188\n",
            "Epoch 5/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0190 - val_loss: 0.0188\n",
            "Epoch 6/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0189 - val_loss: 0.0175\n",
            "Epoch 7/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0184 - val_loss: 0.0176\n",
            "Epoch 8/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0184 - val_loss: 0.0178\n",
            "Epoch 9/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0183 - val_loss: 0.0193\n",
            "Epoch 10/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0184 - val_loss: 0.0178\n",
            "Epoch 11/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0183 - val_loss: 0.0173\n",
            "Epoch 12/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0181 - val_loss: 0.0173\n",
            "Epoch 13/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0180 - val_loss: 0.0176\n",
            "Epoch 14/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0181 - val_loss: 0.0172\n",
            "Epoch 15/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0177 - val_loss: 0.0175\n",
            "Epoch 16/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0174 - val_loss: 0.0175\n",
            "Epoch 17/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0179 - val_loss: 0.0173\n",
            "Epoch 18/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0174 - val_loss: 0.0181\n",
            "Epoch 19/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0176 - val_loss: 0.0181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp4gj8q6rn/97of49id.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp4gj8q6rn/ftwa0nke.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=90551', 'data', 'file=/tmp/tmp4gj8q6rn/97of49id.json', 'init=/tmp/tmp4gj8q6rn/ftwa0nke.json', 'output', 'file=/tmp/tmp4gj8q6rn/prophet_model2mj1lqjh/prophet_model-20241227122345.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "12:23:45 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "12:23:51 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "WS 앙상블 모델 성능:\n",
            "MSE: 0.0864\n",
            "MAE: 0.2691\n",
            "R2 Score: -1.7896\n",
            "\n",
            "HM 모델 학습 중...\n",
            "중복된 인덱스 발견. 첫 번째 값만 유지합니다.\n",
            "\n",
            "Fold 1/5\n",
            "Epoch 1/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2466 - val_loss: 0.0442\n",
            "Epoch 2/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0482 - val_loss: 0.0334\n",
            "Epoch 3/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0249 - val_loss: 0.0278\n",
            "Epoch 4/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0195 - val_loss: 0.0129\n",
            "Epoch 5/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0166 - val_loss: 0.0119\n",
            "Epoch 6/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0150 - val_loss: 0.0112\n",
            "Epoch 7/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0136 - val_loss: 0.0108\n",
            "Epoch 8/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0130 - val_loss: 0.0147\n",
            "Epoch 9/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0122 - val_loss: 0.0096\n",
            "Epoch 10/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0111 - val_loss: 0.0099\n",
            "Epoch 11/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0109 - val_loss: 0.0114\n",
            "Epoch 12/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0100 - val_loss: 0.0154\n",
            "Epoch 13/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0101 - val_loss: 0.0151\n",
            "Epoch 14/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0097 - val_loss: 0.0189\n",
            "\n",
            "Fold 2/5\n",
            "Epoch 1/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0119 - val_loss: 0.0143\n",
            "Epoch 2/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0102 - val_loss: 0.0146\n",
            "Epoch 3/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0091 - val_loss: 0.0130\n",
            "Epoch 4/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0089 - val_loss: 0.0169\n",
            "Epoch 5/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0085 - val_loss: 0.0141\n",
            "Epoch 6/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0116\n",
            "Epoch 7/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0188\n",
            "Epoch 8/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0176\n",
            "Epoch 9/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0165\n",
            "Epoch 10/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0074 - val_loss: 0.0137\n",
            "Epoch 11/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0070 - val_loss: 0.0138\n",
            "\n",
            "Fold 3/5\n",
            "Epoch 1/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0094 - val_loss: 0.0098\n",
            "Epoch 2/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0115\n",
            "Epoch 3/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0109\n",
            "Epoch 4/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0125\n",
            "Epoch 5/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0076 - val_loss: 0.0102\n",
            "Epoch 6/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0111\n",
            "\n",
            "Fold 4/5\n",
            "Epoch 1/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0093\n",
            "Epoch 2/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0105\n",
            "Epoch 3/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0097\n",
            "Epoch 4/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0108\n",
            "Epoch 5/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0107\n",
            "Epoch 6/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0071 - val_loss: 0.0103\n",
            "\n",
            "Fold 5/5\n",
            "Epoch 1/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0112\n",
            "Epoch 2/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0090\n",
            "Epoch 3/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0077 - val_loss: 0.0158\n",
            "Epoch 4/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0164\n",
            "Epoch 5/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0077\n",
            "Epoch 6/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0074 - val_loss: 0.0088\n",
            "Epoch 7/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0122\n",
            "Epoch 8/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0087\n",
            "Epoch 9/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0069 - val_loss: 0.0098\n",
            "Epoch 10/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp4gj8q6rn/3l8cpv0s.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp4gj8q6rn/s3hut68b.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=1823', 'data', 'file=/tmp/tmp4gj8q6rn/3l8cpv0s.json', 'init=/tmp/tmp4gj8q6rn/s3hut68b.json', 'output', 'file=/tmp/tmp4gj8q6rn/prophet_modelb88xwdht/prophet_model-20241227123053.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "12:30:53 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "12:31:05 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "HM 앙상블 모델 성능:\n",
            "MSE: 187.2769\n",
            "MAE: 13.6812\n",
            "R2 Score: -5239.7957\n",
            "\n",
            "WD 모델 학습 중...\n",
            "중복된 인덱스 발견. 첫 번째 값만 유지합니다.\n",
            "\n",
            "Fold 1/5\n",
            "Epoch 1/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1739 - val_loss: 0.0571\n",
            "Epoch 2/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0561 - val_loss: 0.0517\n",
            "Epoch 3/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0471 - val_loss: 0.0518\n",
            "Epoch 4/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0437 - val_loss: 0.0480\n",
            "Epoch 5/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0425 - val_loss: 0.0451\n",
            "Epoch 6/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0393 - val_loss: 0.0423\n",
            "Epoch 7/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0382 - val_loss: 0.0453\n",
            "Epoch 8/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0383 - val_loss: 0.0560\n",
            "Epoch 9/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0390 - val_loss: 0.0441\n",
            "Epoch 10/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0349 - val_loss: 0.0484\n",
            "Epoch 11/50\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0354 - val_loss: 0.0429\n",
            "\n",
            "Fold 2/5\n",
            "Epoch 1/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0403 - val_loss: 0.0366\n",
            "Epoch 2/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0390 - val_loss: 0.0361\n",
            "Epoch 3/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0372 - val_loss: 0.0360\n",
            "Epoch 4/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0363 - val_loss: 0.0353\n",
            "Epoch 5/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0358 - val_loss: 0.0362\n",
            "Epoch 6/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0350 - val_loss: 0.0360\n",
            "Epoch 7/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0342 - val_loss: 0.0360\n",
            "Epoch 8/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0341 - val_loss: 0.0355\n",
            "Epoch 9/50\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0340 - val_loss: 0.0354\n",
            "\n",
            "Fold 3/5\n",
            "Epoch 1/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0352 - val_loss: 0.0400\n",
            "Epoch 2/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0347 - val_loss: 0.0388\n",
            "Epoch 3/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0346 - val_loss: 0.0398\n",
            "Epoch 4/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0335 - val_loss: 0.0377\n",
            "Epoch 5/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0334 - val_loss: 0.0378\n",
            "Epoch 6/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0330 - val_loss: 0.0370\n",
            "Epoch 7/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0327 - val_loss: 0.0380\n",
            "Epoch 8/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0324 - val_loss: 0.0365\n",
            "Epoch 9/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0320 - val_loss: 0.0368\n",
            "Epoch 10/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0320 - val_loss: 0.0369\n",
            "Epoch 11/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0317 - val_loss: 0.0411\n",
            "Epoch 12/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0313 - val_loss: 0.0395\n",
            "Epoch 13/50\n",
            "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0309 - val_loss: 0.0370\n",
            "\n",
            "Fold 4/5\n",
            "Epoch 1/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0329 - val_loss: 0.0324\n",
            "Epoch 2/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0327 - val_loss: 0.0339\n",
            "Epoch 3/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0327 - val_loss: 0.0310\n",
            "Epoch 4/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0321 - val_loss: 0.0343\n",
            "Epoch 5/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0325 - val_loss: 0.0348\n",
            "Epoch 6/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0318 - val_loss: 0.0322\n",
            "Epoch 7/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0320 - val_loss: 0.0317\n",
            "Epoch 8/50\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0313 - val_loss: 0.0331\n",
            "\n",
            "Fold 5/5\n",
            "Epoch 1/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0313 - val_loss: 0.0429\n",
            "Epoch 2/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0313 - val_loss: 0.0389\n",
            "Epoch 3/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0313 - val_loss: 0.0453\n",
            "Epoch 4/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0310 - val_loss: 0.0472\n",
            "Epoch 5/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0306 - val_loss: 0.0427\n",
            "Epoch 6/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0313 - val_loss: 0.0414\n",
            "Epoch 7/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0302 - val_loss: 0.0385\n",
            "Epoch 8/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0301 - val_loss: 0.0397\n",
            "Epoch 9/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0305 - val_loss: 0.0395\n",
            "Epoch 10/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0304 - val_loss: 0.0391\n",
            "Epoch 11/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0302 - val_loss: 0.0411\n",
            "Epoch 12/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0296 - val_loss: 0.0381\n",
            "Epoch 13/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0296 - val_loss: 0.0380\n",
            "Epoch 14/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0299 - val_loss: 0.0415\n",
            "Epoch 15/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0292 - val_loss: 0.0432\n",
            "Epoch 16/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0293 - val_loss: 0.0381\n",
            "Epoch 17/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0295 - val_loss: 0.0379\n",
            "Epoch 18/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0288 - val_loss: 0.0377\n",
            "Epoch 19/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0286 - val_loss: 0.0417\n",
            "Epoch 20/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0287 - val_loss: 0.0419\n",
            "Epoch 21/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0286 - val_loss: 0.0378\n",
            "Epoch 22/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0290 - val_loss: 0.0407\n",
            "Epoch 23/50\n",
            "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0283 - val_loss: 0.0398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp4gj8q6rn/fwwqzduw.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp4gj8q6rn/xqs9h12d.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=28951', 'data', 'file=/tmp/tmp4gj8q6rn/fwwqzduw.json', 'init=/tmp/tmp4gj8q6rn/xqs9h12d.json', 'output', 'file=/tmp/tmp4gj8q6rn/prophet_modeln5hl8b43/prophet_model-20241227123934.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "12:39:34 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "12:39:43 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "WD 앙상블 모델 성능:\n",
            "MSE: 14.2862\n",
            "MAE: 3.7657\n",
            "R2 Score: -239.8635\n",
            "\n",
            "예측할 날짜와 시간을 입력하세요 (형식: YYYY/MM/DD/HH:MM, 종료는 'q'): 2023/01/05/03:00\n",
            "\n",
            "예측 성능 평가:\n",
            "\n",
            "TA 예측 성능:\n",
            "MAE: 10.8847\n",
            "MSE: 119.4822\n",
            "R2 Score: -298.5376\n",
            "\n",
            "RN 예측 성능:\n",
            "MAE: 1.7100\n",
            "MSE: 2.9533\n",
            "R2 Score: 0.0000\n",
            "\n",
            "WS 예측 성능:\n",
            "MAE: 0.7188\n",
            "MSE: 0.6474\n",
            "R2 Score: -1.5417\n",
            "\n",
            "HM 예측 성능:\n",
            "MAE: 360.7752\n",
            "MSE: 131722.4686\n",
            "R2 Score: -16637.6276\n",
            "\n",
            "WD 예측 성능:\n",
            "MAE: 123.3387\n",
            "MSE: 15425.8035\n",
            "R2 Score: -97.7954\n",
            "\n",
            "예측 결과:\n",
            "             DateTime    TA_pred  TA_actual  RN_pred  RN_actual   WS_pred  \\\n",
            "0 2023-01-05 03:00:00 -14.606250       -3.7  -10.539       -9.0  2.449450   \n",
            "1 2023-01-05 04:00:00 -14.880693       -4.3  -10.539       -9.0  2.331902   \n",
            "2 2023-01-05 05:00:00 -15.163409       -4.7  -10.539       -9.0  2.368934   \n",
            "3 2023-01-05 06:00:00 -17.598326       -5.0  -10.881       -9.0  2.929963   \n",
            "4 2023-01-05 07:00:00 -16.755048       -5.3  -10.881       -9.0  3.079317   \n",
            "5 2023-01-05 08:00:00 -14.904680       -5.6  -10.881       -9.0  3.053427   \n",
            "\n",
            "   WS_actual     HM_pred  HM_actual     WD_pred  WD_actual  \n",
            "0        1.5  383.742191         65  131.056024         36  \n",
            "1        1.1  387.725146         66  125.053105          5  \n",
            "2        2.3  391.868964         67  120.558080          2  \n",
            "3        2.3  476.474255         69  139.195329          2  \n",
            "4        2.5  475.585373         71  135.676489          2  \n",
            "5        2.2  460.255370         73  137.493339          2  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-20ea805ad31c>\u001b[0m in \u001b[0;36m<cell line: 545>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-20ea805ad31c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;31m# 사용자로부터 날짜 입력 받기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0minput_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n예측할 날짜와 시간을 입력하세요 (형식: YYYY/MM/DD/HH:MM, 종료는 'q'): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xLnWc6zWCbpp"
      }
    }
  ]
}